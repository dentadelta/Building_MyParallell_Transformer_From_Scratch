{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c227813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Config import conf\n",
    "from transformers import T5Tokenizer\n",
    "from torchtext.nn.modules.multiheadattention import ScaledDotProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ba0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = conf()\n",
    "h = config.h\n",
    "N = config.N\n",
    "dmodel = config.dmodel\n",
    "dk= config.dk\n",
    "dv = config.dv\n",
    "dff = config.dff\n",
    "tokenizer = T5Tokenizer.from_pretrained(config.tokenizer_path)\n",
    "max_length = config.max_length\n",
    "vocab_size = config.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb858ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1input = 'I love dog'\n",
    "sentence2input = 'I love cat'\n",
    "sentence3input = 'I love money'\n",
    "sentence4input = 'I love overtime'\n",
    "\n",
    "decoder1input_ = 'dog meat is delicious'\n",
    "sentence2input_ = 'cat meat is bad '\n",
    "sentence3input_ = 'I can buy dogs'\n",
    "sentence4input_ = 'I can buy cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c565b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tokenizer.batch_encode_plus([sentence1input,sentence2input,sentence3input,sentence4input],\n",
    "                                          max_length= max_length,\n",
    "                                          pad_to_max_length = True,\n",
    "                                          truncation=True,\n",
    "                                          return_tensors='pt'\n",
    "                                         )\n",
    "encoder_inputs = encoder_inputs['input_ids'].to('cuda:0')\n",
    "\n",
    "\n",
    "decoder_inputs = tokenizer.batch_encode_plus([sentence1input,sentence2input,sentence3input,sentence4input],\n",
    "                                          max_length= max_length,\n",
    "                                          pad_to_max_length = True,\n",
    "                                          truncation=True,\n",
    "                                          return_tensors='pt'\n",
    "                                         )\n",
    "decoder_inputs = decoder_inputs['input_ids'].to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621e9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 1]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def create_mask(sequence_length,cuda_number):\n",
    "    mask = (torch.triu(torch.ones(sequence_length, sequence_length)) == 1).transpose(-2, -1).to(cuda_number)\n",
    "    mask = mask.int().masked_fill(mask == 0, 0)\n",
    "    return mask\n",
    "\n",
    "#example:\n",
    "example_mask = create_mask(4,'cuda:0')\n",
    "print(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341d3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len, vocab_size):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embedded_layer = nn.Embedding(vocab_size,d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedded_layer(x)\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a6ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttentionHead(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,cuda_number='cuda:0', applyMask = False):\n",
    "        super(SingleAttentionHead,self).__init__()\n",
    "        self.proj_key = nn.Linear(dmodel,dk).to(cuda_number)\n",
    "        self.proj_query = nn.Linear(dmodel,dk).to(cuda_number)\n",
    "        self.proj_value  = nn.Linear(dmodel,dv).to(cuda_number)\n",
    "        self.dk = dk\n",
    "        self.cuda_number = cuda_number\n",
    "        self.max_length = max_length\n",
    "        self.applyMask = applyMask\n",
    "        \n",
    "    def forward(self,x,y=None):\n",
    "        x = x.to(self.cuda_number)\n",
    "        k = self.proj_key(x)\n",
    "        if y == None: #If you dont supply a y value value then this is the self attended layer\n",
    "            q = self.proj_query(x)\n",
    "            v = self.proj_value(x)\n",
    "            \n",
    "        if y != None:  # If you need a mask then this is the encoder-decoder attention layer\n",
    "            y = y.to(self.cuda_number)\n",
    "            q = self.proj_query(y)  #y is encoder output, you get the query from the encoder\n",
    "            v = self.proj_value(y)  #y is the encoder output, you get the key from the encoder\n",
    "        \n",
    "        I = torch.einsum('b i d , b j d -> b i j', q, k)\n",
    "        \n",
    "        if self.applyMask and y == None: #If you need a mask then this is the decoder-self attended layer\n",
    "            mask = create_mask(self.max_length,self.cuda_number)\n",
    "            for i in range(len(I)):\n",
    "                I[i].masked_fill_(mask==0,float('-inf'))\n",
    "        \n",
    "        attention = F.softmax(I/(self.dk**0.5), dim=-1)\n",
    "        \n",
    "        head = torch.einsum('b i j , b j d -> b i d', attention, v)\n",
    "        \n",
    "        if self.cuda_number != 'cuda:0':\n",
    "            return head.to('cuda:0')\n",
    "        return head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3487cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttentionHead(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,applyMask = False):\n",
    "        super(MultiAttentionHead, self).__init__()\n",
    "        \n",
    "        nlayers_GPU_0 = int(h/2)\n",
    "        nlayers_GPU_1 = int(h/2)\n",
    "        \n",
    "        self.head_GPU0 = nn.ModuleList([\n",
    "            SingleAttentionHead(dmodel,dk,dv,max_length,'cuda:0',applyMask) for i in range(nlayers_GPU_0)\n",
    "        ])\n",
    "        \n",
    "        self.head_GPU1 = nn.ModuleList([\n",
    "            SingleAttentionHead(dmodel,dk,dv,max_length,'cuda:1',applyMask) for i in range(nlayers_GPU_1)\n",
    "        ])\n",
    "        #Weight_0 layer:\n",
    "        self.W0 = nn.Linear(dmodel,dmodel).to('cuda:0')   #Size h*dv x dmodel. But since dv = dk and dk x h = dv so it's a dmodel x dmodel layer -> cuda:0\n",
    "        #LayerNormalisation\n",
    "        self.Add_and_Nom = nn.LayerNorm(dmodel, eps=1e-05, elementwise_affine=True).to('cuda:0')\n",
    "        self.dropout = nn.Dropout(0.1).to('cuda:0')\n",
    "    \n",
    "    def forward(self,x,y=None):\n",
    "        multi_attention_heads = 'Empty'\n",
    "        for i, l in enumerate(self.head_GPU0):\n",
    "            if i == 0:\n",
    "                multi_attention_heads = l(x,y)\n",
    "            else:\n",
    "                multi_attention_heads = torch.cat((multi_attention_heads,l(x,y)), dim=2)\n",
    "        for i, l in enumerate(self.head_GPU1):\n",
    "            multi_attention_heads = torch.cat((multi_attention_heads,l(x,y)), dim=2)\n",
    "        multi_attention_heads = self.W0(multi_attention_heads) \n",
    "        multi_attention_heads = self.Add_and_Nom(x + multi_attention_heads)  #cuda:0\n",
    "        multi_attention_heads = self.dropout(multi_attention_heads)\n",
    "        return multi_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5a3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length):\n",
    "        super(EncoderStack, self).__init__()\n",
    "        self.multiAttentionHeads = MultiAttentionHead(dmodel,dk,dv,max_length,False)\n",
    "        self.lin1a = nn.Linear(dmodel,dff).to('cuda:0')\n",
    "        self.dropout1 = nn.Dropout(0.1).to('cuda:0')\n",
    "        self.lin1b = nn.Linear(dff,dmodel).to('cuda:0')\n",
    "        self.Add_and_Nom = nn.LayerNorm(dmodel, eps=1e-05, elementwise_affine=True).to('cuda:0')\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.multiAttentionHeads(x)\n",
    "        sublayer_x = self.lin1a(x)\n",
    "        sublayer_x = F.relu(sublayer_x)\n",
    "        sublayer_x = self.dropout1(sublayer_x)\n",
    "        sublayer_x = self.lin1b(sublayer_x)\n",
    "        sublayer_x = self.Add_and_Nom(x + sublayer_x)\n",
    "        return sublayer_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b98137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length):\n",
    "        super(DecoderStack, self).__init__()\n",
    "        self.masked_multi_head_attention = MultiAttentionHead(dmodel,dk,dv,max_length,True)\n",
    "        self.multi_head_attention = MultiAttentionHead(dmodel,dk,dv,max_length,False)\n",
    "        self.lin1a = nn.Linear(dmodel,dff).to('cuda:0')\n",
    "        self.dropout1 = nn.Dropout(0.1).to('cuda:0')\n",
    "        self.lin1b = nn.Linear(dff,dmodel).to('cuda:0')\n",
    "        self.Add_and_Nom = nn.LayerNorm(dmodel, eps=1e-05, elementwise_affine=True).to('cuda:0')\n",
    "\n",
    "    def forward(self,x,y=None):\n",
    "        z = self.masked_multi_head_attention(x)\n",
    "        z = self.multi_head_attention(x,y)\n",
    "        sublayer_z = self.lin1a(z)\n",
    "        sublayer_z = F.relu(sublayer_z)\n",
    "        sublayer_z = self.dropout1(sublayer_z)\n",
    "        sublayer_z = self.lin1b(sublayer_z)\n",
    "        sublayer_z = self.Add_and_Nom(z + sublayer_z)\n",
    "        return sublayer_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e027d754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTransformerStacks(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length):\n",
    "        super(EncoderTransformerStacks, self).__init__()\n",
    "        self.encoderStack = nn.ModuleList([\n",
    "            EncoderStack(dmodel,dk,dv,max_length) for i in range(6)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for i, l in enumerate(self.encoderStack):\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04713d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTransformerStacks(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length):\n",
    "        super(DecoderTransformerStacks, self).__init__()\n",
    "        self.dencoderStack = nn.ModuleList([\n",
    "            DecoderStack(dmodel,dk,dv,max_length) for i in range(6)\n",
    "        ])\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        for i, l in enumerate(self.dencoderStack):\n",
    "            x = l(x,y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7aeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderTransformer(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,vocab_size):\n",
    "        super(EncoderTransformer, self).__init__()\n",
    "        self.positionEncoder = PositionalEncoding(dmodel,0.1, max_length,vocab_size).to('cuda:0')\n",
    "        self.encoder_Stacks = EncoderTransformerStacks(dmodel,dk,dv,max_length)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.positionEncoder(x)\n",
    "        x = self.encoder_Stacks(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6a65e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderTransformer(nn.Module):\n",
    "    def __init__(self,dmodel,dk,dv,max_length,vocab_size):\n",
    "        super(DecoderTransformer, self).__init__()\n",
    "        self.positionEncoder = PositionalEncoding(dmodel,0.1, max_length,vocab_size).to('cuda:0')\n",
    "        self.decoder_Stacks = DecoderTransformerStacks(dmodel,dk,dv,max_length)\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        x = self.positionEncoder(x)\n",
    "        x = self.decoder_Stacks(x,y)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4da26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = create_mask(decoder_inputs.size(1),'cuda:0')\n",
    "new_sequence = 'empty'\n",
    "for i in range(len(decoder_inputs)):\n",
    "    decoder_sequence = torch.cat(max_length*[decoder_inputs[i]]).view(max_length,-1)\n",
    "    decoder_sequence = decoder_sequence.masked_fill_(mask==0,0)\n",
    "    if i == 0:\n",
    "        new_sequence = decoder_sequence\n",
    "    else:\n",
    "        new_sequence = torch.cat((new_sequence,decoder_sequence),dim=0)\n",
    "new_sequence = new_sequence.view(decoder_inputs.size(0),decoder_inputs.size(1),-1).permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f336c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   27,     0,     0,     0,     0,     0],\n",
       "         [   27,     0,     0,     0,     0,     0],\n",
       "         [   27,     0,     0,     0,     0,     0],\n",
       "         [   27,     0,     0,     0,     0,     0]],\n",
       "\n",
       "        [[   27,   333,     0,     0,     0,     0],\n",
       "         [   27,   333,     0,     0,     0,     0],\n",
       "         [   27,   333,     0,     0,     0,     0],\n",
       "         [   27,   333,     0,     0,     0,     0]],\n",
       "\n",
       "        [[   27,   333,  1782,     0,     0,     0],\n",
       "         [   27,   333,  1712,     0,     0,     0],\n",
       "         [   27,   333,   540,     0,     0,     0],\n",
       "         [   27,   333, 22624,     0,     0,     0]],\n",
       "\n",
       "        [[   27,   333,  1782,     1,     0,     0],\n",
       "         [   27,   333,  1712,     1,     0,     0],\n",
       "         [   27,   333,   540,     1,     0,     0],\n",
       "         [   27,   333, 22624,     1,     0,     0]],\n",
       "\n",
       "        [[   27,   333,  1782,     1,     0,     0],\n",
       "         [   27,   333,  1712,     1,     0,     0],\n",
       "         [   27,   333,   540,     1,     0,     0],\n",
       "         [   27,   333, 22624,     1,     0,     0]],\n",
       "\n",
       "        [[   27,   333,  1782,     1,     0,     0],\n",
       "         [   27,   333,  1712,     1,     0,     0],\n",
       "         [   27,   333,   540,     1,     0,     0],\n",
       "         [   27,   333, 22624,     1,     0,     0]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequence  #This sequence will be enumerate on the decoder side, while keeping the encoder \n",
    "                #outputs the same until the entire sequence-batch is enumerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f68d82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss = ...\n",
    "#Criterion = ...\n",
    "#Optimiser = ...\n",
    "#Scaler= \n",
    "Encoder = EncoderTransformer(dmodel,dk,dv,max_length,vocab_size)\n",
    "encoder_outputs = Encoder(encoder_inputs)\n",
    "\n",
    "#for sequence in new_sequence:\n",
    "for i in range(1): #testing my code for the first batch sequence\n",
    "    decoder = DecoderTransformer(dmodel,dk,dv,max_length,vocab_size)\n",
    "    output = decoder(new_sequence[0],encoder_outputs)\n",
    "    print(output)\n",
    "    #final_linear_layer = nn.Linear(x,x)     #Need a bit research\n",
    "    #output = final_linear_layer(output)\n",
    "    #output = F.softmax(output,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1273fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.2559e-01, -9.5723e-01, -1.6681e-01,  ..., -1.5691e-02,\n",
       "           3.3745e-01,  1.9378e+00],\n",
       "         [ 1.7054e+00,  6.7709e-02, -1.6083e-01,  ...,  6.3935e-01,\n",
       "           1.0993e+00,  3.8847e-01],\n",
       "         [ 1.0393e-02,  9.1850e-01, -1.8591e+00,  ...,  2.6690e-01,\n",
       "           3.5427e-01, -1.8566e-01],\n",
       "         [-4.0424e-01,  3.5961e-01,  1.5181e-01,  ...,  8.8463e-01,\n",
       "           2.6146e-02,  4.8610e-01],\n",
       "         [-1.1620e-01, -1.8751e-01, -1.2720e+00,  ..., -2.6234e-01,\n",
       "           7.3851e-01,  1.3576e+00],\n",
       "         [ 1.2964e+00,  2.7380e-01,  2.3247e-01,  ..., -7.7654e-01,\n",
       "           3.2613e-01, -4.0830e-01]],\n",
       "\n",
       "        [[ 6.7240e-01, -8.2397e-01,  1.9303e-01,  ..., -9.0539e-01,\n",
       "          -1.8578e+00,  1.3617e-01],\n",
       "         [ 1.1636e+00,  1.9351e-01, -2.1027e-01,  ..., -5.8921e-02,\n",
       "           4.0367e-01,  3.0951e-01],\n",
       "         [ 7.5501e-01,  5.5409e-01, -7.1989e-01,  ...,  2.1878e-01,\n",
       "          -4.6132e-01,  1.5635e+00],\n",
       "         [ 1.7250e+00, -2.3884e-01, -9.8896e-01,  ...,  5.5359e-01,\n",
       "          -5.3528e-02,  3.0019e-01],\n",
       "         [ 1.9058e+00,  4.4292e-01, -1.2182e+00,  ..., -3.3815e-01,\n",
       "          -2.0433e-01, -2.4617e-02],\n",
       "         [ 2.2888e+00, -1.0805e-01,  1.9352e-01,  ...,  6.4046e-01,\n",
       "           3.1349e-01,  1.1587e+00]],\n",
       "\n",
       "        [[-4.4381e-01,  7.9697e-01,  8.9082e-01,  ..., -5.6435e-01,\n",
       "          -2.0202e+00,  2.3070e+00],\n",
       "         [-1.1629e-01, -1.4709e-01,  3.3153e-01,  ..., -1.7220e+00,\n",
       "          -4.6259e-01,  2.7971e-01],\n",
       "         [-3.9472e-02,  5.6682e-01, -2.7931e-01,  ..., -4.3475e-01,\n",
       "           6.1065e-01,  1.2379e+00],\n",
       "         [ 3.1680e-01, -9.5482e-01, -5.6896e-01,  ...,  3.5157e-01,\n",
       "           7.2875e-01,  1.9639e+00],\n",
       "         [ 3.5842e-01,  1.5346e-01, -8.8644e-01,  ...,  3.9830e-01,\n",
       "           8.1987e-02,  1.2967e+00],\n",
       "         [-5.2038e-01,  6.1806e-01, -1.4499e-01,  ...,  3.6814e-01,\n",
       "           6.6301e-01,  1.1854e+00]],\n",
       "\n",
       "        [[ 5.8836e-01, -7.2628e-01,  6.3529e-01,  ..., -5.4760e-02,\n",
       "          -2.1486e+00,  2.3650e+00],\n",
       "         [ 5.6256e-01,  6.4763e-02, -6.9168e-01,  ...,  3.1426e-01,\n",
       "           1.2617e+00,  2.9020e-01],\n",
       "         [ 5.9125e-01, -8.8013e-01,  4.0136e-01,  ..., -8.1970e-01,\n",
       "          -6.1723e-01,  8.4580e-01],\n",
       "         [ 4.7199e-02, -9.4947e-01, -1.4792e+00,  ...,  1.0725e-03,\n",
       "           1.2944e+00,  3.3324e-01],\n",
       "         [ 8.2010e-02, -9.7831e-02,  2.8883e-01,  ..., -7.4115e-01,\n",
       "           2.1173e-01,  1.1700e+00],\n",
       "         [ 3.7157e-01,  4.6924e-01, -2.5358e-02,  ..., -1.8094e-01,\n",
       "           3.2391e-01,  1.8604e+00]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22968b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
